---
title: "Log or not - Analysis of ECDC forecasts"
output: html_document
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE, 
                      warning = FALSE)

library(scoringutils)
library(purrr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(patchwork)
library(stringr)
library(here)
library(data.table)
library(kableExtra)
library(performance)
library(tidytext)

recompute_scores <- FALSE

# situations with negative values: France 2021-05-22, CZ 2021-08-07, ES 2021-03-06
```

```{r}
# helper functions
# ------------------------------------------------------------------------------

make_table <- function(x, caption = "") {
  x %>%
    rename_all(gsub, pattern = "_", replacement = " ") %>%
    rename_all(str_to_sentence) %>%
    mutate_if(is.numeric, round, 2) %>%
    kable(caption = caption) %>%
    kable_styling()
}

# format plot scales
scale_fn <- function(x) {
  ifelse(x >= 1000000, 
         paste0(x / 1000000, "m"), 
         ifelse(x >= 5000,
                paste0(x / 1000, "k"),
                x))
}

label_fn <- function(x) {
  ifelse(x < 1000, 
         paste(x), 
         ifelse(x < 1e6, 
                paste0(x / 1000, "k"),
                ifelse(x < 1e9, 
                       paste0(x / 1e6, "m"), 
                       paste0(x / 1e9, "b"))
                )
         )
}



```

```{r}
# load data 
# ------------------------------------------------------------------------------
hub_data <- rbindlist(list(
  fread(here("data", "full-data-european-forecast-hub-1.csv")), 
  fread(here("data", "full-data-european-forecast-hub-2.csv")),
  fread(here("data", "full-data-european-forecast-hub-3.csv"))
)) |>
  unique()
```

```{r eval = recompute_scores}
# score forecasts
# ------------------------------------------------------------------------------

# helper function
score_forecasts <- function(data,
                            summarise_by = c("model", "location", 
                                             "target_end_date", "forecast_date",
                                             "horizon", "target_type"), 
                            scale = c("natural", "log")) {
  if (scale[1] == "log") {
    data <- data |>
      mutate(prediction = log(pmax(prediction, 0) + 1), 
             true_value = log(pmax(true_value, 0) + 1))
  }
  
  data |>
    eval_forecasts(summarise_by = summarise_by) |>
    mutate(scale = scale[1])
}

scores_natural <- score_forecasts(hub_data)
scores_log <- score_forecasts(hub_data, scale = "log")

scores_gr_natural <- score_forecasts(growth_data)
scores_gr_log <- score_forecasts(growth_data, scale = "log")

scores <- bind_rows(scores_natural, scores_log)
fwrite(scores, here("output", "data", "all-scores-european-hub.csv"))

scores_gr <- bind_rows(scores_gr_natural, scores_gr_log)
fwrite(scores_gr, here("output", "data", "all-scores-growth-rate-european-hub.csv"))
```

```{r}
scores <- fread(here("output", "data", "all-scores-european-hub.csv"))
scores[, scale := factor(scale, levels = c("natural", "log"))]
data.table::setnames(scores, old = c("aem", "sharpness"), new = c("ae_median", "dispersion"))

scores_gr <- fread(here("output", "data", "all-scores-growth-rate-european-hub.csv"))
scores_gr[, scale := factor(scale, levels = c("natural", "log"))]
```

General thoughts?

- Focus on Hub-ensemble or average across all models? 
- Focus on two weeks ahead? 

## =============================================================================
## FIGURE 4
## Mean vs. sd of observed values

```{r}
# average number of cases and deaths

# plot with means across locations ---------------------------------------------
label_fn_within <- function(x) {
  x <- gsub(pattern = "___Deaths", "", x)
  x <- gsub(pattern = "___Cases", "", x)
  paste(x)
}

mean_observations <- hub_data |>
  dplyr::select(location, target_type, target_end_date, true_value) |>
  unique() |>
  group_by(target_type, location) |>
  summarise(mean_value = mean(true_value), 
            sd_value = sd(true_value), 
            var_value = var(true_value))
  
plot_means_obs <- mean_observations |>
  ggplot(aes(y = mean_value, x = reorder_within(location, -mean_value, target_type))) + 
  geom_bar(stat = "identity", fill = "grey50") + 
  facet_wrap(~ target_type, scales = "free") + 
  theme_scoringutils() + 
  scale_y_continuous(labels = label_fn) + 
  scale_x_discrete(guide = guide_axis(n.dodge=2), labels = label_fn_within) + 
  labs(y = "Mean observed value", x = "Location")

plot_df <- scores |> 
  filter(model == "EuroCOVIDhub-ensemble", 
         horizon == 2) |>
  group_by(target_type, location, scale) |>
  summarise(interval_score = mean(interval_score), 
            .groups = "drop_last") |> 
  full_join(mean_observations)

plot_mean_scores <- plot_df |>
  ggplot(aes(y = interval_score,
             x = reorder_within(location, -mean_value, target_type))) + 
  geom_bar(stat = "identity") + 
  scale_fill_brewer(palette = "Set1", name = "Forecast target") + 
  facet_wrap(scale ~ target_type, scale = "free") + 
  theme_scoringutils() + 
  theme(legend.position = "none") + 
  scale_y_continuous(labels = scale_fn) + 
  scale_x_discrete(guide = guide_axis(n.dodge=2), labels = label_fn_within) +
  labs(y = "Interval score", x = "Location") 

plot_means_obs / 
  plot_mean_scores + 
  plot_layout(heights = c(1, 2))

ggsave("output/figures/HUB-mean-obs-location.png", width = 9, height = 7)

# This uses the ensemble, but alternatively, we could think about just summarising across all models for these plots? 
```


Figure that shows Variance vs. mean of the observations. Makes the point that the
data looks neg. binomial. 
```{r}
# plot with mean vs. variance --------------------------------------------------
hub_data |>
  dplyr::select(location, target_type, target_end_date, true_value) |>
  unique() |>
  group_by(location, target_type) |>
  summarise(mean_value = mean(true_value), 
            sd_value = sd(true_value), 
            var_value = var(true_value)) |>
  ggplot(aes(y = var_value, x = mean_value)) +
  geom_point() + 
  facet_wrap(~ target_type, scales = "free") + 
  scale_x_continuous(trans = "log10", labels = label_fn) +
  scale_y_continuous(trans = "log10", labels = label_fn) +
  # scale_x_continuous(labels = label_fn) +
  # scale_y_continuous(labels = label_fn) +
  labs(y = "Variance observed value", x = "Mean observed value") + 
  geom_function(fun = function(x) {x + x^2}, linetype = "dashed", size = 0.5) + 
  theme_scoringutils() + 
  geom_smooth(alpha = 0.2, size = 0.2)

ggsave("output/figures/HUB-mean-var-obs.png", width = 7, height = 2.5)
  
```



## Scores across forecast targets

This uses the Hub ensemble

```{r}
scores |>
  dplyr::select(location, target_type, scale, target_end_date, interval_score) |>
  unique() |>
  group_by(target_type, scale) |>
  summarise(mean_value = mean(interval_score), 
            sd_value = sd(interval_score), 
            var_value = var(interval_score))

scores |> 
  filter(model == "EuroCOVIDhub-ensemble", 
         horizon == 2) |>
  ggplot(aes(y = interval_score, x = target_type)) + 
  geom_violin(aes(fill = target_type), alpha = 0.2, color = NA) + 
  geom_boxplot(alpha = 0.5) + 
  scale_fill_brewer(palette = "Set1", name = "Forecast target") + 
  facet_wrap(~ scale, scale = "free") + 
  theme_scoringutils() + 
  theme(legend.position = "none") + 
  scale_y_continuous(labels = scale_fn, trans = "log10") + 
  labs(y = "Interval score", x = "Target type")

ggsave("output/figures/HUB-average-scores.png", width = 7, height = 2.5)
```

Mean scores: 
```{r}
scores |> 
  filter(model == "EuroCOVIDhub-ensemble", 
         horizon == 2) |>
  group_by(scale, target_type) |>
  summarise(interval_score = mean(interval_score), 
            .groups = "drop_last") |>
  make_table()
```


## Correlation between scores

```{r}
scores |> 
  filter(model == "EuroCOVIDhub-ensemble", 
         horizon == 2) |>
  group_by(target_type, location, scale) |>
  summarise(interval_score = mean(interval_score), 
            .groups = "drop_last") %>%
  pivot_wider(values_from = interval_score, names_from = scale) %>%
  group_by(target_type) %>%
  summarise(correlation = cor(natural, log))
```





## Change of average scores for increasing forecast horizons

```{r}
scores |> 
  filter(model == "EuroCOVIDhub-ensemble") |>
  group_by(scale, target_type, horizon) |>
  summarise(interval_score = mean(interval_score), 
            .groups = "drop_last") |>
  mutate(multiplicative_score = interval_score / min(interval_score)) |>
  ggplot(aes(y = multiplicative_score, x = horizon)) + 
  geom_line() + 
  geom_point() + 
  facet_grid(scale ~ target_type) + 
  theme_scoringutils() + 
  labs(x = "Forecast horizon in weeks", y = "Multplicative change in interval score")

ggsave("output/figures/HUB-scores-over-horizon.png", width = 7, height = 4)

```


## Comparison of the distribution of model rankings

```{r}
rankings <- scores |>
  select(-c(coverage_deviation, bias, ae_median, dispersion, underprediction, overprediction)) |>
  group_by(location, forecast_date, horizon, target_type, scale) |>
  mutate(ranking = rank(interval_score) / n()) |>
  ungroup()

rankings_wide <- rankings |>
  select(model, location, target_end_date, forecast_date, horizon,
         interval_score, scale, ranking, target_type) |>
  pivot_wider(names_from = scale, values_from = ranking, 
              id_cols = -interval_score)

plot_ranking_diffs <- function(
  rankings, 
  rankings_wide,
  target_type
) {
  type <- target_type
  # maybe replace this by the same ranking for all plots
  factor_levels <- rankings |>
    filter(horizon == 2, scale == "natural", target_type == type) |>
    group_by(model) |>
    summarise(ranking = mean(ranking)) |>
    arrange(-ranking) |>
    pull(model)
  
  # p_rankings <- rankings |>
  #   filter(horizon == 2) |>
  #   mutate(model = factor(model, levels = factor_levels)) |>
  #   ggplot(aes(y = model, x = ranking)) +
  #   ggdist::stat_halfeye() +
  #   facet_wrap(~ scale) +
  #   theme_scoringutils() +
  #   labs(y = "Model", x = "Normalised ranking")

  
  ranking_plot <- function(
    hor
  ) {
    p <- rankings_wide |>
      mutate(diff_ranking = natural - log) |>
      mutate(model = factor(model, levels = factor_levels)) |>
      filter(horizon == hor, 
             !is.na(model)) |>
      ggplot(aes(y = model, x = diff_ranking)) +
      geom_vline(linetype = "dashed", xintercept = 0, 
                 size = 0.6, color = "grey40") +
      ggdist::stat_pointinterval() +
      theme_scoringutils() +
      labs(y = "", x = "Differences in ranking") 
    
    if (hor > 1) {
      p <- p +
        theme(axis.text.y = element_blank(), 
              axis.ticks.y = element_blank(), 
              axis.line.y = element_blank())
    }
    return(p)
  }
  
  ranking_plot(hor = 1) + ranking_plot(2) + ranking_plot(3) + ranking_plot(4) +
    plot_layout(nrow = 1)
}

# should probably have one plot for both cases and deaths since this is rankings
p_diff_cases <- plot_ranking_diffs(rankings, rankings_wide, 
                                   target_type = "Cases")

ggsave(filename = "output/figures/HUB-ranking-diffs.png", 
       plot = p_diff_cases,
       width = 9, height = 5)
```

## Look at pairwise comparisons

```{r}
summarised_pairwise <- scores |>
  filter(target_type == "Cases") |>
  summarise_scores(by = c("model", "scale"), relative_skill = TRUE)

ranking_natural <- 
  summarised_pairwise |>
  filter(scale == "natural") |>
  arrange(-relative_skill) |>
  pull(model)

plot_rel_skill <- summarised_pairwise |>
  mutate(model = factor(model, levels = ranking_natural)) |>
  ggplot(aes(y = model, x = relative_skill)) +
  geom_bar(stat = "identity") +
  theme_scoringutils() +
  facet_wrap(~scale) +
  labs(y = "Model", x = "Relative skill")
  
diffs <- summarised_pairwise |>
  mutate(model = factor(model, levels = ranking_natural)) |>
  select(model, relative_skill, scale) |>
  pivot_wider(names_from = scale, values_from = relative_skill) |>
  mutate(model = factor(model, levels = ranking_natural), 
         difference = natural - log)

plot_diffs <- diffs |>
  mutate(title = "difference") |>
  ggplot(aes(y = model, x = difference)) +
  geom_bar(stat = "identity") +
  theme_scoringutils() +
  labs(y = "Model", x = "Difference in relative skill") +
  theme(axis.title.y = element_blank(), 
        axis.text.y = element_blank(), 
        axis.ticks.y = element_blank(), 
        axis.line.y = element_blank()) +
  facet_wrap(~title)

plot_distr_scores <- scores |>
  filter(horizon == 2) |>
  mutate(model = factor(model, levels = ranking_natural)) |>
  ggplot(aes(y = model, x = interval_score)) +
  ggdist::stat_pointinterval() +
  facet_wrap(~ scale, scale = "free_x") +
  theme_scoringutils() +
  scale_x_log10(labels = label_fn) +
  theme(axis.title.y = element_blank(), 
        axis.text.y = element_blank(), 
        axis.ticks.y = element_blank(), 
        axis.line.y = element_blank()) +
  labs(y = "Model", x = "WIS") 

plot_rel_wis <- scores |>
  filter(horizon == 2, 
         target_type == "Cases") |>
  mutate(model = factor(model, levels = ranking_natural)) |>
  summarise_scores(by = c("model", "scale")) |>
  plot_wis(relative_contributions = FALSE) +
    theme(axis.title.y = element_blank(), 
        axis.text.y = element_blank(), 
        axis.ticks.y = element_blank(), 
        axis.line.y = element_blank()) +
  scale_x_continuous(labels = label_fn) +
  facet_wrap(~scale, scales = "free_x")

plot_rel_skill + plot_diffs + plot_rel_wis + #plot_distr_scores +
  plot_layout(widths = c(2, 1, 2)) &
  plot_layout(guides = "collect") &
  theme(legend.position = "bottom")

ggsave("output/figures/HUB-pairwise-comparisons.png", width = 9, height = 5)

#Issues: this currently ignores that some models have only made forecasts for one location. They should usually be excluded, but maybe not necessary here as we're really more comparing the results for natural and log rather than the models against each other.
```


# Correlations for ranks, scores and pairwise comparisons

```{r}
# correlation between values
hub_data |>
  select(location, target_end_date, target_type, true_value) |>
  unique() |>
  mutate(log_obs = log(pmax(true_value, 0) + 1)) |>
  group_by(target_type) |>
  summarise(cor = cor(true_value, log_obs))

# correlation between scores
cor_scores <- scores |>
  filter(horizon <=4) |>
  select(interval_score, scale, forecast_date, model, horizon, location, target_type) |>
  pivot_wider(names_from = scale, values_from = interval_score) |>
  group_by(horizon, target_type) |>
  summarise(cor = cor(natural, log), 
            spearman = cor(natural, log))

cor_scores |> 
  mutate(`Target type` = target_type) |>
  ggplot(aes(x = horizon, y = cor, 
             fill = `Target type`, color = `Target type`)) + 
  geom_histogram(stat = "identity", position = "dodge") +
  theme_scoringutils() + 
  coord_cartesian(ylim = c(0, 1)) +
  labs(y = "Correlation (scores natural vs. log)", x = "Forecast horizon")


# Correlation between ranks when going from natural to log
correlation_ranks <- rankings_wide |>
  filter(horizon < 5) |>
  group_by(horizon, target_type) |>
  summarise(cor = cor(natural, log)) |>
  rename(`Target type` = target_type)
  
plot_cor_ranks <- correlation_ranks |>
  ggplot(aes(x = horizon, y = cor, 
             fill = `Target type`, color = `Target type`)) + 
  geom_histogram(stat = "identity", position = "dodge") +
  theme_scoringutils() + 
  coord_cartesian(ylim = c(0, 1)) +
  labs(y = "Correlation (rank natural vs. log)", x = "Forecast horizon")

ggsave(filename = "output/figures/HUB-cor-ranks.png", width = 7, height = 4.5, 
       plot = plot_cor_ranks)


# Correlation between pairwise comparisons
correlation_rel_skill <- scores |>
  filter(horizon < 5) |>
  summarise_scores(
    by = c("model", "scale", "horizon", "target_type"), 
    relative_skill = TRUE) |>
  select(model, horizon, target_type, relative_skill, scale) |>
  pivot_wider(values_from = relative_skill, names_from = scale) |>
  group_by(horizon, target_type) |>
  summarise(cor = cor(natural, log)) 
  
plot_cor_skill <- correlation_rel_skill |>
  rename(`Target type` = target_type) |>
  ggplot(aes(x = horizon, y = cor, fill = `Target type`, color = `Target type` )) + 
  # geom_line() +
  # geom_point() +
  geom_histogram(stat = "identity", position = "dodge") +
  theme_scoringutils() + 
  coord_cartesian(ylim = c(0, 1)) +
  labs(y = "Correlation (rel. skill natural vs. log)", x = "Forecast horizon")

ggsave(filename = "output/figures/HUB-cor-rel-skill.png", width = 7, height = 4.5, 
       plot = plot_cor_skill)

plot_cors <- plot_cor_ranks + plot_cor_skill +
  plot_layout(guides = "collect") & 
  theme(legend.position = "bottom")

ggsave(filename = "output/figures/HUB-cors-skill-rank.png", width = 7, height = 3, 
       plot = plot_cors)

```


Example comparisons of forecasts on the log and the natural scale

```{r}
# "CovidMetrics-epiBATS" only has forecasts in DE
# "ICM-agentModel" only in Poland
# "UVA is everywhere

plot_pred_score <- function(hub_data, scores, model,
                            horizon = 2, type = "Cases") {
  forecast_model <- model
  h <- horizon
  filtered_hub <- hub_data |>
    filter(model == forecast_model, 
           horizon %in% h, 
           target_type == type) 
  
  locations <- unique(filtered_hub$location) 
  
  filtered_scores <- scores |>
    filter(model == forecast_model, 
           horizon %in% h, 
           location %in% locations,
           target_type == type) 
  
  plot_natural  <- filtered_hub |>  
    plot_predictions(x = "target_end_date") +
    scale_y_continuous(labels = label_fn)  +
    theme(legend.position = "bottom")
  
  plot_log <- filtered_hub |>
    mutate(prediction = log(prediction + 1), 
           true_value = log(true_value + 1)) |>
    plot_predictions(x = "target_end_date") +
    scale_y_continuous(labels = label_fn)  +
    theme(legend.position = "bottom")
  
  scores_natural <- filtered_scores |>
    filter(scale == "natural") |>
    summarise_scores("target_end_date") |>
    mutate(target_end_date = factor(target_end_date)) |>
    plot_wis(x = "target_end_date", flip = TRUE) +
    scale_x_continuous(labels = label_fn)
  
  scores_log <- filtered_scores |>
    filter(scale == "log") |>
    summarise_scores("target_end_date") |>
    mutate(target_end_date = factor(target_end_date)) |>
    plot_wis(x = "target_end_date", flip = TRUE)
  
  (plot_natural + plot_log) /
    (scores_natural + scores_log) +
    plot_layout(guides = "collect") &
    theme(legend.position = "bottom")
}


ICM <- plot_pred_score(hub_data, scores, "ICM-agentModel")

epiBATS <- plot_pred_score(hub_data, scores, "CovidMetrics-epiBATS")

BSLCoV <- plot_pred_score(hub_data, scores, "UB-BSLCoV")

ggsave(filename = "output/figures/HUB-model-ICM.png", width = 9, height = 5, plot = ICM)
ggsave(filename = "output/figures/HUB-model-epiBATS.png", width = 9, height = 5, plot = epiBATS)
ggsave(filename = "output/figures/HUB-model-BSLCoV.png", width = 9, height = 5, plot = BSLCoV)


```


# Table with relevant values

```{r}
summary <- hub_data |>
  filter(horizon == 2) |>
  mutate(natural = true_value, 
         log = log(pmax(0, true_value) +1)) |>
  select(location, target_type, target_end_date, natural, log) |>
  pivot_longer(cols = c(natural, log), values_to = "true_value", names_to = "scale") |>
  unique() |>
  group_by(target_type, scale) |>
  summarise(mean = mean(true_value), 
            sd = sd(true_value), 
            var = var(true_value))
  
table_obs <- summary |>
  pivot_longer(cols = c(mean, sd, var), names_to = "measure") |>
  pivot_wider(values_from = value, names_from = scale) |>
  select(target_type, measure, natural, log) |>
  mutate(quantity = "Observations", 
         natural = round(natural), 
         log = round(log, 2)) |>
  select(target_type, quantity, measure, natural, log)

table_scores <- scores |> 
  filter(model == "EuroCOVIDhub-ensemble", 
         horizon == 2) |>
  group_by(target_type, scale) |>
  summarise(mean = mean(interval_score), 
            sd = sd(interval_score), 
            .groups = "drop_last") |>
  pivot_longer(cols = c(mean, sd), names_to = "measure") |>
  pivot_wider(values_from = value, names_from = scale) |>
 mutate(quantity = "WIS", 
         natural = round(natural), 
         log = round(log, 2)) |>
  select(target_type, quantity, measure, natural, log)
  
table <- rbind(table_obs, 
               table_scores) |>
  arrange(quantity, target_type, measure)



table |>
  kable(format = "latex", booktabs = TRUE,
        align = c("l", "l", "l", rep("c", 2)),
        # col.names = c(" ", names(scores)[-(1:2)])) %>%
  ) #|>
  # collapse_rows(columns = 1) %>%
  # kable_styling(latex_options = c("scale_down",
  #                                 "hold_position")) %>%
  # column_spec(1, background = "white") %>%
  # pack_rows("Observations", 1, 6, indent = FALSE,
  #           hline_after = TRUE) %>%
  # pack_rows("WIS", 7, 10, indent = FALSE,
  #           hline_after = TRUE)

```


































--- 
# Code parking lot

## Scores over time
restrict to a few locations, e.g. GB, FR, ES (highest average scores there)

```{r}
scores |> 
  filter(model == "EuroCOVIDhub-ensemble",
         location %in% c("GB", "ES", "DE"),
         horizon == 2) |>
  rename(Location = location) |>
  group_by(target_type, scale, Location) |>
  mutate(multiplicative_score = interval_score / min(interval_score)) |>
  ggplot(aes(y = multiplicative_score, x = forecast_date, colour = Location)) + 
  geom_line() + 
  geom_point() + 
  facet_grid(target_type ~ scale, scale = "free_y") + 
  theme_scoringutils() + 
  labs(x = "Forecast date", y = "WIS relative to smallest observed value")

ggsave("output/figures/HUB-scores-over-time.png", width = 7, height = 5)
```

*Overall it looks like there can still be substantial fluctuation in log scores, but maybe slightly less than when scored on an absolute scale. Interestingly, it seems like the smoothing effect is stronger for deaths than for cases.*

```{r}
# create version of data where the true value is the true growth rate
# interesting question: does it make a difference, whether we transform it 
# to be the weekly growth rate, i.e. take the n-th root, where n is the horizon? 

latest_truth <- fread(here("data", "weekly-truth-Europe.csv")) |>
  rename(last_known_true_value = true_value) |>
  mutate(forecast_date = target_end_date + 2) |>
  select(location, target_type, forecast_date, last_known_true_value) |>
  unique()

# unsure whether the pmax hack is the right way to do it
growth_data <- hub_data |>
  inner_join(latest_truth) |>
  mutate(true_value = true_value / pmax(last_known_true_value + 1),
         prediction = prediction / pmax(last_known_true_value + 1)) |>
  select(-last_known_true_value)
```

## Variance of scores vs. mean of scores across locations 

```{r}
scores |> 
  filter(model == "EuroCOVIDhub-ensemble", 
         horizon == 2) |>
  group_by(target_type, location, scale) |>
  summarise(mean_wis = mean(interval_score), 
            sd_wis = sd(interval_score), 
            .groups = "drop_last") |>
  ggplot(aes(y = sd_wis, x = mean_wis)) + 
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", size = 0.5) + 
  geom_point() + 
  facet_wrap(~ target_type + scale, scale = "free") + 
  theme_scoringutils() + 
  theme(legend.position = "none") + 
  # scale_x_continuous(labels = scale_fn) + 
  # scale_y_continuous(labels = scale_fn) + 
  scale_x_continuous(labels = scale_fn, trans = "log10") +
  scale_y_continuous(labels = scale_fn, trans = "log10") +
  labs(x = "Mean WIS", y = "Sd of WIS") 

ggsave("output/figures/HUB-sd-vs-mean-scores.png", width = 7, height = 5)
```

```{r}
# negative binomial
# MASS::glm.nb(true_value ~ target_type, 
#        data = hub_data %>%
#          mutate(true_value = pmax(true_value, 0)), 
#        link = "identity")
```

## WIS vs. the totsl number of observed values
probably not needed anymore, as we have similar things

```{r}
wis_vs_total <- function(scores, summary_fct = mean, fulldata = hub_data) {
  
  total_values <- 
    fulldata |> 
    filter(!is.na(prediction)) |>
    group_by(location, target_type, target_end_date) |>
    summarise(true_value = unique(true_value)) |>
    group_by(location, target_type) |>
    summarise(total = sum(true_value))
  
  plot_df <- scores |> 
    filter(model == "EuroCOVIDhub-ensemble", 
           horizon == 2) |>
    group_by(target_type, location, scale) |>
    summarise(wis = summary_fct(interval_score), 
              .groups = "drop_last") |> 
    inner_join(total_values) 
  
  plot_df |>
    group_by(target_type, scale) |>
    summarise(correlation = cor(wis, total)) |> 
    print()
  
  plot_df |>
    ggplot(aes(y = wis, x = total)) + 
    geom_point() + 
    facet_wrap(~ target_type + scale, scale = "free") + 
    theme_scoringutils() + 
    theme(legend.position = "none") + 
    scale_x_continuous(labels = scale_fn) +
    scale_y_continuous(labels = scale_fn) +
    labs(y = "REPLACE", x = "Total number of observed values")
} 

wis_vs_total(scores) + 
  labs(y = "Mean WIS")
ggsave("output/figures/HUB-mean-scores-vs-total.png", width = 7, height = 5)

wis_vs_total(scores, summary_fct = stats::sd) + 
  labs(y = "Sd WIS")
ggsave("output/figures/HUB-sd-scores-vs-total.png", width = 7, height = 5)


# log-log versions of that plot
wis_vs_total(scores) + 
  labs(y = "Mean WIS") + 
  scale_x_continuous(labels = scale_fn, trans = "log10") +
  scale_y_continuous(labels = scale_fn, trans = "log10") 
ggsave("output/figures/HUB-mean-scores-vs-total-log-log.png", width = 7, height = 5)

wis_vs_total(scores, summary_fct = stats::sd) + 
  labs(y = "Sd WIS") + 
  scale_x_continuous(labels = scale_fn, trans = "log10") +
  scale_y_continuous(labels = scale_fn, trans = "log10") 
ggsave("output/figures/HUB-sd-scores-vs-total-log-log.png", width = 7, height = 5)

# correlation



```

Test for a single example forecast to verify that rankings change
```{r}
# we see that rankings change even for a single forecast. So we need to check everything is still correct. 
# take one example
test_data <- hub_data |>
  filter(model %in% c("MUNI-ARIMA", "epiforecasts-EpiNow2"), 
         forecast_date == "2021-10-18", 
         target_type == "Cases", 
         location == "AT")

test_data |>
  score(metrics = c("interval_score")) |>
  summarise_scores()

test_data |>
  mutate(prediction = log(prediction), 
         true_value = log(true_value)) |>
  score(metrics = c("interval_score")) |>
  summarise_scores()
## indeed everything seems to be correct, but rankings still change FOR A SINGLE FORECAST. 
# It seems this is because the trade-off between calibration and sharpness changes? 
# need to check in what way
```


## Distribution of scores

```{r}
scores |>
  ggplot(aes(x = interval_score)) + 
  geom_density() + 
  facet_wrap(~ target_type + scale, scale = "free") + 
  scale_x_continuous(labels = scale_fn)
```

## Fit a model to data

Check fit of the log scale model
```{r echo=TRUE}
reg_log <- scores |>
  filter(scale == "log") |>
  glm(formula = interval_score ~ 1 + model + location + target_type + horizon, 
      family = gaussian)
```

```{r}
# check distribution
performance::check_distribution(reg_log) |>
  plot()

# check normality of residuals
check_normality(reg_log) |>
  plot(type = "qq")

# heteroskedasticity of error terms - the plot takes extremly long to run
performance::check_heteroskedasticity(reg_log)
# performance::check_heteroskedasticity(reg_log) |>
#   plot()

# check influence of outliers - plot also takes very long to run
performance::check_outliers(reg_log)
# performance::check_outliers(reg_log) |>
#   plot()

```



--- 

# Growth Rate stuff - Looking at growth rates directly

## Scores of the growth rate across targets

This uses the Hub ensemble
```{r}
scores_gr |> 
  filter(model == "EuroCOVIDhub-ensemble", 
         horizon == 2) |>
  ggplot(aes(y = interval_score, x = target_type)) + 
  geom_violin(aes(fill = target_type), alpha = 0.2, color = NA) + 
  geom_boxplot(alpha = 0.5) + 
  scale_fill_brewer(palette = "Set1", name = "Forecast target") + 
  facet_wrap(~ scale, scale = "free") + 
  theme_scoringutils() + 
  theme(legend.position = "none") + 
  scale_y_continuous(labels = scale_fn, trans = "log10") + 
  labs(y = "Interval score", x = "Target type")
```
*Scoring the growth rate makes things more comparable*

Mean scores: 
```{r}
scores_gr |> 
  filter(model == "EuroCOVIDhub-ensemble", 
         horizon == 2) |>
  group_by(scale, target_type) |>
  summarise(interval_score = mean(interval_score), 
            .groups = "drop_last") |>
  make_table()
```

## Scores for the growth rate across locations
```{r}
scores_gr |> 
  filter(model == "EuroCOVIDhub-ensemble", 
         horizon == 2) |>
  group_by(target_type, location, scale) |>
  summarise(interval_score = mean(interval_score), 
            .groups = "drop_last") |>
  ggplot(aes(y = interval_score, x = reorder(location, -interval_score))) + 
  geom_bar(stat = "identity") + 
  scale_fill_brewer(palette = "Set1", name = "Forecast target") + 
  facet_wrap(~ target_type + scale, scale = "free") + 
  theme_scoringutils() + 
  theme(legend.position = "none") + 
  scale_y_continuous(labels = scale_fn) + 
  labs(y = "Interval score", x = "Target type")
```

## Scores for growth rate over time
restrict to a few locations, e.g. GB, FR, ES (highest average scores there)

UK: 
```{r}
scores_gr |> 
  filter(model == "EuroCOVIDhub-ensemble",
         location == "GB",
         horizon == 2) |>
  group_by(target_type, scale) |>
  mutate(multiplicative_score = interval_score / min(interval_score)) |>
  ggplot(aes(y = multiplicative_score, x = forecast_date)) + 
  geom_line() + 
  geom_point() + 
  facet_grid(target_type ~ scale, scale = "free_y") + 
  theme_scoringutils() + 
  labs(x = "Forecast date", y = "WIS relative to smallest observed value")
```

France: Looks like a data revision
```{r}
scores_gr |> 
  filter(model == "EuroCOVIDhub-ensemble",
         location == "FR",
         horizon == 2) |>
  group_by(target_type, scale) |>
  mutate(multiplicative_score = interval_score / min(interval_score)) |>
  ggplot(aes(y = multiplicative_score, x = forecast_date)) + 
  geom_line() + 
  geom_point() + 
  facet_grid(target_type ~ scale, scale = "free_y") + 
  theme_scoringutils() + 
  labs(x = "Forecast date", y = "WIS relative to smallest observed value")
```

Spain: 
```{r}
scores_gr |> 
  filter(model == "EuroCOVIDhub-ensemble",
         location == "ES",
         horizon == 2) |>
  group_by(target_type, scale) |>
  mutate(multiplicative_score = interval_score / min(interval_score)) |>
  ggplot(aes(y = multiplicative_score, x = forecast_date)) + 
  geom_line() + 
  geom_point() + 
  facet_grid(target_type ~ scale, scale = "free_y") + 
  theme_scoringutils() + 
  labs(x = "Forecast date", y = "WIS relative to smallest observed value")
```

## Change of average scores for the growth rate for increasing forecast horizons
```{r}
scores_gr |> 
  filter(model == "EuroCOVIDhub-ensemble") |>
  group_by(scale, target_type, horizon) |>
  summarise(interval_score = mean(interval_score), 
            .groups = "drop_last") |>
  mutate(multiplicative_score = interval_score / min(interval_score)) |>
  ggplot(aes(y = multiplicative_score, x = horizon)) + 
  geom_line() + 
  geom_point() + 
  facet_grid(target_type ~ scale) + 
  theme_scoringutils() + 
  labs(x = "Forecast horizon in weeks", y = "Multplicative change in interval score")
```

## Distribution of scores growth rate

```{r}
scores_gr |>
  ggplot(aes(x = interval_score)) + 
  geom_density() + 
  facet_wrap(~ target_type + scale, scale = "free") + 
  scale_x_continuous(labels = scale_fn)
```

## Fit a model to growth rate data

Check fit of the log scale model
```{r echo=TRUE}
reg_gr <- scores_gr |>
  filter(scale == "natural") |>
  glm(formula = interval_score ~ 1 + model + location + target_type + horizon, 
      family = gaussian)

reg_gr_log <- scores_gr |>
  filter(scale == "log") |>
  glm(formula = interval_score ~ 1 + model + location + target_type + horizon, 
      family = gaussian)
```

Check distribution
```{r}
# check distribution
performance::check_distribution(reg_gr_log) |>
  plot()

# check normality of residuals
check_normality(reg_gr_log) |>
  plot(type = "qq")

# heteroskedasticity of error terms - the plot takes extremly long to run
performance::check_heteroskedasticity(reg_gr_log)
# performance::check_heteroskedasticity(reg_log) |>
#   plot()

# check influence of outliers - plot also takes very long to run
performance::check_outliers(reg_gr_log)
# performance::check_outliers(reg_log) |>
#   plot()

```



