\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{apalike}
\citation{reichCollaborativeMultiyearMultimodel2019,funkShorttermForecastsInform2020,cramerEvaluationIndividualEnsemble2021,bracherShorttermForecastingCOVID192021,europeancovid-19forecasthubEuropeanCovid19Forecast2021,sherrattPredictivePerformanceMultimodel2022}
\citation{timmermannForecastingMethodsFinance2018,elliottForecastingEconomicsFinance2016}
\citation{gneitingWeatherForecastingEnsemble2005,kukkonenReviewOperationalRegionalscale2012}
\citation{gneitingStrictlyProperScoring2007}
\citation{bracherEvaluatingEpidemicForecasts2021}
\citation{europeancovid-19forecasthubEuropeanCovid19Forecast2021,sherrattPredictivePerformanceMultimodel2022}
\citation{cramerEvaluationIndividualEnsemble2021}
\citation{bracherShorttermForecastingCOVID192021}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Log transforming forecasts and observations}{4}{section.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Scores for different forecasts evaluated the WIS and the log WIS. We simulated 1000 observations $Y_i = {\rm  e}^{x_i}$, with $x_i \text  {iid} \sim \mathcal  {N}(0, 1)$. We then simulated 20 forecasters who would issue a predictive distribution $F = {\rm  e}^{x_i}$, with $x \sim \mathcal  {N}(0, \sigma )$, with values of $\sigma $ ranging from 0.1 to 2.}}{4}{figure.1}\protected@file@percent }
\newlabel{fig:log-improper}{{1}{4}{Scores for different forecasts evaluated the WIS and the log WIS. We simulated 1000 observations $Y_i = {\rm e}^{x_i}$, with $x_i \text {iid} \sim \mathcal {N}(0, 1)$. We then simulated 20 forecasters who would issue a predictive distribution $F = {\rm e}^{x_i}$, with $x \sim \mathcal {N}(0, \sigma )$, with values of $\sigma $ ranging from 0.1 to 2}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Scoring multplicative errors}{5}{subsection.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Weighted interval score for a forecast distribution that is N(1, 0.2) and different observed values. Top: difference in absolute terms. Bottom: difference in relative terms. Interesting panels are top left and bottom right.}}{5}{figure.2}\protected@file@percent }
\newlabel{fig:change-in-scores}{{2}{5}{Weighted interval score for a forecast distribution that is N(1, 0.2) and different observed values. Top: difference in absolute terms. Bottom: difference in relative terms. Interesting panels are top left and bottom right}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Approximately scoring the growth rate}{6}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Effects on model rankings}{6}{subsection.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Simulation showing how the relationship between mean and variance of the forecast quantity affects scores. 1,000 samples were drawn from different negative binomial distributions and scores were computed assuming an ideal forecaster (forecast distribution equal to data-generating distribution). Observations were simulated for different means of the negative-binomial distributions (representing, for example, the number of cases in differently sized states) as well as different relationships between mean and variance (representing, for example, three different infectious processes). The variance of the negative binomial is given as $\sigma ^2 = \mu + \mu ^2 / \theta $, meaning that for large theta the negative binomial distribution is equal to the poisson distribution. We used values of $\theta = 0.1$ (red), 1 (green) and 1b (blue). To make the scores for the different distributios comparable, scores were normalised to one, meaning that the mean score for every distribution (red, green, blue) is one. A: Normalised WIS for ideal forecasts with increasing means of three distribution with different relationships between mean and variance. B: Same plot as A with both axes log-transformed. MAYBE CAN GET RID OF B.}}{7}{figure.3}\protected@file@percent }
\newlabel{fig:SIM-wis-state-size-mean}{{3}{7}{Simulation showing how the relationship between mean and variance of the forecast quantity affects scores. 1,000 samples were drawn from different negative binomial distributions and scores were computed assuming an ideal forecaster (forecast distribution equal to data-generating distribution). Observations were simulated for different means of the negative-binomial distributions (representing, for example, the number of cases in differently sized states) as well as different relationships between mean and variance (representing, for example, three different infectious processes). The variance of the negative binomial is given as $\sigma ^2 = \mu + \mu ^2 / \theta $, meaning that for large theta the negative binomial distribution is equal to the poisson distribution. We used values of $\theta = 0.1$ (red), 1 (green) and 1b (blue). To make the scores for the different distributios comparable, scores were normalised to one, meaning that the mean score for every distribution (red, green, blue) is one. A: Normalised WIS for ideal forecasts with increasing means of three distribution with different relationships between mean and variance. B: Same plot as A with both axes log-transformed. MAYBE CAN GET RID OF B}{figure.3}{}}
\citation{europeancovid-19forecasthubEuropeanCovid19Forecast2021,sherrattPredictivePerformanceMultimodel2022}
\@writefile{toc}{\contentsline {section}{\numberline {3}Empirical example: the European Forecast Hub}{8}{section.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Observations and scores across locations and forecast horizons. A, Average (across all time points) of observed cases and deaths for different locations. B: Boxplot (y-axis on log-scale) of all cases and deaths. C: Scores for two-week-ahead forecasts from the EuroCOVIDhub-ensemble (averaged across all forecast dates) for different locations, evaluated on the natural as well as the logarithmic scale. D: Corresponding box-plots of all individual scores for two-week-ahead predictions. E: Boxplots for the relative change of scores for the EuroCOVIDhub-ensemble across forecast horizons. For any given forecast date and location, forecasts were made for four different forecast horizons, resulting in four scores. All scores were divided by the score for forecast horizon one.}}{9}{figure.4}\protected@file@percent }
\newlabel{fig:HUB-mean-locations}{{4}{9}{Observations and scores across locations and forecast horizons. A, Average (across all time points) of observed cases and deaths for different locations. B: Boxplot (y-axis on log-scale) of all cases and deaths. C: Scores for two-week-ahead forecasts from the EuroCOVIDhub-ensemble (averaged across all forecast dates) for different locations, evaluated on the natural as well as the logarithmic scale. D: Corresponding box-plots of all individual scores for two-week-ahead predictions. E: Boxplots for the relative change of scores for the EuroCOVIDhub-ensemble across forecast horizons. For any given forecast date and location, forecasts were made for four different forecast horizons, resulting in four scores. All scores were divided by the score for forecast horizon one}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Correlations between observations and scores. A: Mean WIS for two-week-ahead predictions of the EuroCOVIDhub-ensemble against the average number of observations in a location. B: Average Spearman (rank-) correlation of scores for individual forecasts from \textit  {all} models. For every individual target (defined by a combination of forecast date, target type, horizon, location), one score was obtained per model. Then, the rank correlation was computed between the scores for all models on the natural scale vs. on the log scale. All rank correlations were averaged and stratified by horizon and target type. C: Correlation between relative skill scores. For every forecast horizon and target type, a separate rel. skill score was computed per model using pairwise comparisons. The plot shows the correlation between the rel. skill scores on the natural vs. on the log scale.}}{10}{figure.5}\protected@file@percent }
\newlabel{fig:HUB-cors}{{5}{10}{Correlations between observations and scores. A: Mean WIS for two-week-ahead predictions of the EuroCOVIDhub-ensemble against the average number of observations in a location. B: Average Spearman (rank-) correlation of scores for individual forecasts from \textit {all} models. For every individual target (defined by a combination of forecast date, target type, horizon, location), one score was obtained per model. Then, the rank correlation was computed between the scores for all models on the natural scale vs. on the log scale. All rank correlations were averaged and stratified by horizon and target type. C: Correlation between relative skill scores. For every forecast horizon and target type, a separate rel. skill score was computed per model using pairwise comparisons. The plot shows the correlation between the rel. skill scores on the natural vs. on the log scale}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces  Forecasts and scores for two-week-ahead predictions from the EuroCOVIDhub-ensemble made in Germany. A, E: 50\% and 90\% prediction intervals and observed values for cases and deaths on the natural scale. B, F: Corresponding scores. C, G: Forecasts and observations on the log scale. D, H: Corresponding scores. }}{11}{figure.6}\protected@file@percent }
\newlabel{fig:HUB-model-comparison-ensemble}{{6}{11}{Forecasts and scores for two-week-ahead predictions from the EuroCOVIDhub-ensemble made in Germany. A, E: 50\% and 90\% prediction intervals and observed values for cases and deaths on the natural scale. B, F: Corresponding scores. C, G: Forecasts and observations on the log scale. D, H: Corresponding scores}{figure.6}{}}
\@writefile{toc}{\contentsline {paragraph}{SAM}{11}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{11}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{summary of what we did}{11}{section*.3}\protected@file@percent }
\citation{bracherEvaluatingEpidemicForecasts2021}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Changes in model ratings as measured by relative skill for two-week-ahead predictions. Top row: cases, bottom row: deaths. NEED TO CHANGE THE ANNOTATION LEVELS.}}{12}{figure.7}\protected@file@percent }
\newlabel{fig:HUB-pairwise}{{7}{12}{Changes in model ratings as measured by relative skill for two-week-ahead predictions. Top row: cases, bottom row: deaths. NEED TO CHANGE THE ANNOTATION LEVELS}{figure.7}{}}
\@writefile{toc}{\contentsline {paragraph}{context, implications, limitations}{12}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{outlook, future work}{12}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Other transformations - maybe move to Discussion}{12}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {A}Supplementary information}{14}{appendix.A}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Table with summary statistics for observations and scores for forecasts from the ECDC data set.}}{14}{table.1}\protected@file@percent }
\newlabel{tab:HUB-summary}{{1}{14}{Table with summary statistics for observations and scores for forecasts from the ECDC data set}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Additional information on the WIS}{14}{subsection.A.1}\protected@file@percent }
\newlabel{wis}{{A.1}{14}{Additional information on the WIS}{subsection.A.1}{}}
\@writefile{toc}{\contentsline {paragraph}{WIS}{14}{section*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Additional information on the CRPS}{14}{subsection.A.2}\protected@file@percent }
\newlabel{crps}{{A.2}{14}{Additional information on the CRPS}{subsection.A.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces My current thinking is that the top row is helpful, as it explalins what the mean / var relationship is which is relevant for how much weight small countries get. I think the 2nd row is just completely useless. The 3rd and 4th row may be helpful. In some sense it is duplicated information from above, but it gives some nice intuiton for the correlations. I could alternatively also turn it into a correlation plot and add it to the other one. }}{15}{figure.8}\protected@file@percent }
\newlabel{fig:HUB-mean-scores-total-loglog}{{8}{15}{My current thinking is that the top row is helpful, as it explalins what the mean / var relationship is which is relevant for how much weight small countries get. I think the 2nd row is just completely useless. The 3rd and 4th row may be helpful. In some sense it is duplicated information from above, but it gives some nice intuiton for the correlations. I could alternatively also turn it into a correlation plot and add it to the other one}{figure.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Scoring the growth rate directly}{16}{subsection.A.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4}Changes in the WIS for forecasts on the log scale}{16}{subsection.A.4}\protected@file@percent }
\newlabel{wis-log-derivation}{{A.4}{16}{Changes in the WIS for forecasts on the log scale}{subsection.A.4}{}}
\bibdata{log-or-not.bib}
\bibcite{bracherEvaluatingEpidemicForecasts2021}{{1}{2021a}{{Bracher et~al.}}{{}}}
\bibcite{bracherShorttermForecastingCOVID192021}{{2}{2021b}{{Bracher et~al.}}{{}}}
\bibcite{cramerEvaluationIndividualEnsemble2021}{{3}{2021}{{Cramer et~al.}}{{}}}
\newlabel{eqn:is-log}{{29}{17}{Changes in the WIS for forecasts on the log scale}{equation.A.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.5}Additional figures}{17}{subsection.A.5}\protected@file@percent }
\bibcite{elliottForecastingEconomicsFinance2016}{{4}{2016}{{Elliott and Timmermann}}{{}}}
\bibcite{europeancovid-19forecasthubEuropeanCovid19Forecast2021}{{5}{2021}{{European Covid-19 Forecast Hub}}{{}}}
\bibcite{funkShorttermForecastsInform2020}{{6}{2020}{{Funk et~al.}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Placeholder}}{18}{figure.9}\protected@file@percent }
\newlabel{fig:placeholder}{{9}{18}{Placeholder}{figure.9}{}}
\bibcite{gneitingWeatherForecastingEnsemble2005}{{7}{2005}{{Gneiting and Raftery}}{{}}}
\bibcite{gneitingStrictlyProperScoring2007}{{8}{2007}{{Gneiting and Raftery}}{{}}}
\bibcite{kukkonenReviewOperationalRegionalscale2012}{{9}{2012}{{Kukkonen et~al.}}{{}}}
\bibcite{reichCollaborativeMultiyearMultimodel2019}{{10}{2019}{{Reich et~al.}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Plot with Weighted interval scores against the mean number of observed cases or deaths.}}{19}{figure.10}\protected@file@percent }
\newlabel{fig:HUB-mean-scores-total}{{10}{19}{Plot with Weighted interval scores against the mean number of observed cases or deaths}{figure.10}{}}
\bibcite{sherrattPredictivePerformanceMultimodel2022}{{11}{2022}{{Sherratt et~al.}}{{}}}
\bibcite{timmermannForecastingMethodsFinance2018}{{12}{2018}{{Timmermann}}{{}}}
\gdef \@abspage@last{20}
